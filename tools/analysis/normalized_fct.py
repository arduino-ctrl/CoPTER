import pandas as pd
import matplotlib.pyplot as plt
import re
from pathlib import Path

# -------------------------- å…¨å±€ç»˜å›¾æ ·å¼é…ç½®ï¼ˆæ²¿ç”¨è®ºæ–‡é£æ ¼ï¼‰ --------------------------
plt.rcParams.update({
    'font.family': 'serif',
    'font.serif': ['Times New Roman', 'Computer Modern Roman'],
    'font.size': 60,
    'axes.labelsize': 60,
    'axes.titlesize': 60,
    'legend.fontsize': 50,
    'xtick.labelsize': 60,
    'ytick.labelsize': 60,
    'axes.unicode_minus': False,
    'axes.linewidth': 1.0,
    'grid.linestyle': '--',
    'grid.alpha': 0.6,
    'figure.dpi': 300,
    'text.usetex': False,
})

# -------------------------- æ ·å¼æ˜ å°„ï¼ˆä¿æŒä¸åŸè„šæœ¬ä¸€è‡´ï¼‰ --------------------------
name_mapping = {
    "copter": "CoPT", 
    "acc": "ACC",
    "m4": "SCoPE" 
}
color_map = {
    "copter": "#FF6B00",
    "acc": "#00CC66",
    "m4": "#0066FF",
}
markers = {
    "copter": '^',
    "acc": 'o',
    "m4": 's',
}
line_styles = {
    "copter": '-',
    "acc": '-',
    "m4": '-',
}

# -------------------------- è¾…åŠ©å‡½æ•°ï¼šæ¸…ç†æ•°å€¼å­—ç¬¦ä¸²ï¼ˆå»é™¤é€—å·å’Œç©ºç™½å­—ç¬¦ï¼‰ --------------------------
def clean_numeric_str(s):
    """å»é™¤å­—ç¬¦ä¸²ä¸­çš„é€—å·ã€ç©ºç™½å­—ç¬¦ï¼Œç¡®ä¿èƒ½è½¬æ¢ä¸ºfloat"""
    return s.strip().strip(',').strip()

# -------------------------- æ•°æ®è§£æå‡½æ•°ï¼šä¿®å¤å°ºå¯¸æŒ‡æ ‡åŒ¹é…å†²çª --------------------------
def parse_overall_fct(file_path):
    try:
        with open(file_path, 'r') as f:
            content = f.read()
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            
            # 1. è§£æOverall FCTï¼ˆåŸæœ‰é€»è¾‘ä¿ç•™ï¼‰
            overall_pattern = r"Overall FCT:\s+Avg\s+Mid\s+95th\s+99th\s+(\S+)\s+(\S+)\s+(\S+)\s+(\S+)"
            match_overall = re.search(overall_pattern, content, re.IGNORECASE | re.DOTALL)
            overall_data = None
            
            if match_overall:
                overall_data = {
                    "Avg": float(clean_numeric_str(match_overall.group(1))),
                    "Mid": float(clean_numeric_str(match_overall.group(2))),
                    "95th": float(clean_numeric_str(match_overall.group(3))),
                    "99th": float(clean_numeric_str(match_overall.group(4)))
                }
            else:
                for i, line in enumerate(lines):
                    if "Overall FCT:" in line and "Avg" in line and "Mid" in line and "95th" in line and "99th" in line:
                        if i + 1 < len(lines):
                            vals = re.findall(r"\S+", lines[i+1])
                            if len(vals) >= 4:
                                overall_data = {
                                    "Avg": float(clean_numeric_str(vals[0])),
                                    "Mid": float(clean_numeric_str(vals[1])),
                                    "95th": float(clean_numeric_str(vals[2])),
                                    "99th": float(clean_numeric_str(vals[3]))
                                }
            
            # 2. è§£æ<100KBå°ºå¯¸ï¼ˆç²¾å‡†åŒ¹é…ï¼Œé¿å…æ··æ·†ï¼‰
            small100kb_data = None
            # æ­£åˆ™æ·»åŠ å•è¯è¾¹ç•Œ\bï¼Œç¡®ä¿åŒ¹é…"100KB"è€Œä¸æ˜¯åŒ…å«å®ƒçš„å­—ç¬¦ä¸²
            small100kb_pattern = r"<\s*100KB\b:\s+Avg:\s*(\S+),\s+Mid:\s*\S+,\s+95th:\s*\S+,\s+99th:\s*(\S+)"
            match_small = re.search(small100kb_pattern, content, re.IGNORECASE)
            
            if match_small:
                small100kb_data = {
                    "Small100KB_Avg": float(clean_numeric_str(match_small.group(1))),
                    "Small100KB_99th": float(clean_numeric_str(match_small.group(2)))
                }
            else:
                # è¡Œéå†ç²¾å‡†åŒ¹é…
                for line in lines:
                    # ç¡®ä¿è¡Œä»¥"< 100KB:"å¼€å¤´ï¼ˆæˆ–åŒ…å«å®Œæ•´åŒ¹é…ï¼‰
                    if line.startswith("< 100KB:") or re.match(r"^\s*<\s*100KB\s*:", line):
                        avg_match = re.search(r"Avg:\s*(\S+)", line)
                        p99_match = re.search(r"99th:\s*(\S+)", line)
                        if avg_match and p99_match:
                            small100kb_data = {
                                "Small100KB_Avg": float(clean_numeric_str(avg_match.group(1))),
                                "Small100KB_99th": float(clean_numeric_str(p99_match.group(1)))
                            }
                            break  # æ‰¾åˆ°åç«‹å³é€€å‡ºï¼Œé¿å…é‡å¤åŒ¹é…
            
            # 3. è§£æ>1MBå°ºå¯¸ï¼ˆç²¾å‡†åŒ¹é…ï¼Œé¿å…ä¸>1MBæ··æ·†ï¼‰
            large1MB_data = None
            # æ­£åˆ™æ·»åŠ å•è¯è¾¹ç•Œ\bï¼Œç¡®ä¿åŒ¹é…"1MB"è€Œä¸æ˜¯"1MB"
            large1MB_pattern = r">\s*1MB\b:\s+Avg:\s*(\S+),\s+Mid:\s*\S+,\s+95th:\s*\S+,\s+99th:\s*(\S+)"
            match_large = re.search(large1MB_pattern, content, re.IGNORECASE)
            
            if match_large:
                large1MB_data = {
                    "Large1MB_Avg": float(clean_numeric_str(match_large.group(1))),
                    "Large1MB_99th": float(clean_numeric_str(match_large.group(2)))
                }
            else:
                # è¡Œéå†ç²¾å‡†åŒ¹é…
                for line in lines:
                    # ç¡®ä¿è¡Œä»¥"> 1MB:"å¼€å¤´ï¼ˆæˆ–åŒ…å«å®Œæ•´åŒ¹é…ï¼‰
                    if line.startswith("> 1MB:") or re.match(r"^\s*>\s*1MB\s*:", line):
                        avg_match = re.search(r"Avg:\s*(\S+)", line)
                        p99_match = re.search(r"99th:\s*(\S+)", line)
                        if avg_match and p99_match:
                            large1MB_data = {
                                "Large1MB_Avg": float(clean_numeric_str(avg_match.group(1))),
                                "Large1MB_99th": float(clean_numeric_str(p99_match.group(1)))
                            }
                            break  # æ‰¾åˆ°åç«‹å³é€€å‡ºï¼Œé¿å…é‡å¤åŒ¹é…
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if overall_data and small100kb_data and large1MB_data:
                # æ‰“å°è§£æç»“æœï¼ˆä¾¿äºè°ƒè¯•éªŒè¯ï¼‰
                print(f"âœ… è§£ææˆåŠŸ {file_path.name}:")
                print(f"  <100KB - Avg: {small100kb_data['Small100KB_Avg']:.3f}, 99th: {small100kb_data['Small100KB_99th']:.3f}")
                print(f"  >1MB  - Avg: {large1MB_data['Large1MB_Avg']:.3f}, 99th: {large1MB_data['Large1MB_99th']:.3f}")
                return {**overall_data, **small100kb_data, **large1MB_data}
            
            print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ {file_path.name} ç¼ºå°‘éƒ¨åˆ†æ•°æ®")
            return None
    except Exception as e:
        print(f"âŒ è§£ææ–‡ä»¶ {file_path.name} å¤±è´¥: {e}")
        return None

# -------------------------- è·¯å¾„ä¸æ ¸å¿ƒé…ç½® --------------------------
load_values = [0.2, 0.4, 0.6, 0.8]  # å¾…å¯¹æ¯”çš„è´Ÿè½½å€¼
methods = ["copter", "acc", "m4"]   # å¾…å¯¹æ¯”çš„æ–¹æ³•
base_metrics = ["Avg", "Mid", "95th", "99th"]
size_metrics = ["Small100KB_Avg", "Small100KB_99th", "Large1MB_Avg", "Large1MB_99th"]
all_metrics = base_metrics + size_metrics

base_dir = Path("/home/ame/copter/tools/analysis")  # æ•°æ®æ ¹ç›®å½•
output_dir = Path("/home/ame/copter/tools/analysis/normalized_fct_plots/thesis_websearch_0.05t")  # è¾“å‡ºæ–‡ä»¶å¤¹
output_dir.mkdir(parents=True, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆä¸å­˜åœ¨æ—¶ï¼‰

# -------------------------- æ•°æ®æ”¶é›†ï¼šåŠ è½½æ‰€æœ‰æ–¹æ³•-è´Ÿè½½-æŒ‡æ ‡æ•°æ® --------------------------
all_data = []
print("="*80)
print("ğŸ“¥ å¼€å§‹è§£ææ‰€æœ‰FCTæ–‡ä»¶...")
print("="*80)

for load in load_values:
    load_folder = base_dir / f"thesis_websearch_0.05t_{load}load"
    print(f"\nğŸ“‚ æ­£åœ¨å¤„ç†è´Ÿè½½: {load*100}%")
    for method in methods:
        fct_file = load_folder / f"{method}_thesis_websearch_0.05t_{load}load.fct"
        fct_metrics = parse_overall_fct(fct_file)
        if fct_metrics:
            all_data.append({
                "Load": load,
                "Method": method,
                "Avg": fct_metrics["Avg"],
                "Mid": fct_metrics["Mid"],
                "95th": fct_metrics["95th"],
                "99th": fct_metrics["99th"],
                "Small100KB_Avg": fct_metrics["Small100KB_Avg"],
                "Small100KB_99th": fct_metrics["Small100KB_99th"],
                "Large1MB_Avg": fct_metrics["Large1MB_Avg"],
                "Large1MB_99th": fct_metrics["Large1MB_99th"]
            })

# è½¬æ¢ä¸ºDataFrameï¼Œä¾¿äºæ•°æ®å¤„ç†
df = pd.DataFrame(all_data)
if df.empty:
    print("\nâŒ é”™è¯¯ï¼šæœªæ”¶é›†åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼")
    exit(1)

# ========================== æ‰“å°åŸå§‹æ•°æ®ï¼ˆå«æ–°å¢æŒ‡æ ‡ï¼‰ ==========================
print("\n" + "="*120)
print("ğŸ“Š è§£æåçš„åŸå§‹ FCT æ•°æ®ï¼ˆå•ä½ï¼šé€šå¸¸ä¸ºmsï¼‰")
print("="*120)
df_sorted = df.sort_values(by=["Method", "Load"]).reset_index(drop=True)
pd.options.display.float_format = '{:.3f}'.format
display_cols = ["Load", "Method", "Avg", "Mid", "95th", "99th", 
                "Small100KB_Avg", "Small100KB_99th", "Large1MB_Avg", "Large1MB_99th"]
print(df_sorted[display_cols].to_string(index=False))
print()

# -------------------------- å½’ä¸€åŒ–å¤„ç†ï¼šå«æ–°å¢å°ºå¯¸æŒ‡æ ‡ --------------------------
copter_baseline = df[df["Method"] == "copter"].set_index("Load")

for metric in all_metrics:
    df[f"Normalized_{metric}"] = df.apply(
        lambda row: row[metric] / copter_baseline.loc[row["Load"], metric],
        axis=1
    )

# ========================== æ‰“å°å½’ä¸€åŒ–æ•°æ®ï¼ˆå«æ–°å¢æŒ‡æ ‡ï¼‰ ==========================
print("="*120)
print("ğŸ“ˆ å½’ä¸€åŒ–åçš„æ•°æ®ï¼ˆä»¥ CoPTER ä¸ºåŸºå‡†ï¼Œå€¼è¶Šå°è¶Šä¼˜ï¼‰")
print("="*120)
normalized_cols = ["Load", "Method"] + [f"Normalized_{m}" for m in all_metrics]
df_normalized = df[normalized_cols].sort_values(by=["Method", "Load"]).reset_index(drop=True)
col_rename = {
    "Normalized_Avg": "Norm_Avg",
    "Normalized_Mid": "Norm_Mid",
    "Normalized_95th": "Norm_95th",
    "Normalized_99th": "Norm_99th",
    "Normalized_Small100KB_Avg": "Norm_Small100KB_Avg",
    "Normalized_Small100KB_99th": "Norm_Small100KB_99th",
    "Normalized_Large1MB_Avg": "Norm_Large1MB_Avg",
    "Normalized_Large1MB_99th": "Norm_Large1MB_99th"
}
df_normalized.rename(columns=col_rename, inplace=True)
print(df_normalized.to_string(index=False))
print()

# -------------------------- å›¾è¡¨é…ç½®ï¼šæŒ‡æ ‡-æ ‡é¢˜-æ–‡ä»¶åæ˜ å°„ --------------------------
metric_config = {
    "Avg": ("Average FCT", "avg_fct",{"loc":"upper left"}),
    "Mid": ("Median FCT", "mid_fct",{"loc":"upper left"}),
    "95th": ("95th Percentile FCT", "95th_fct",{"loc":"upper right","bbox_to_anchor":(1.02,1.05)}),
    "99th": ("99th Percentile FCT", "99th_fct",{"loc":"upper right"}),
    "Small100KB_Avg": ("Average FCT (<100KB)", "small100KB_avg_fct",{"loc":"upper right"}),
    "Small100KB_99th": ("99th Percentile FCT (<100KB)", "small100KB_99th_fct",{"loc":"upper right"}),
    "Large1MB_Avg": ("Average FCT (>1MB)", "large1MB_avg_fct",{"loc":"upper left"}),
    "Large1MB_99th": ("99th Percentile FCT (>1MB)", "large1MB_99th_fct",{"loc":"upper left"})
}

# -------------------------- æ‰¹é‡ç»˜åˆ¶ï¼šå«æ–°å¢å°ºå¯¸æŒ‡æ ‡å›¾è¡¨ --------------------------
print("="*80)
print("ğŸ¨ å¼€å§‹ç”Ÿæˆå›¾è¡¨...")
print("="*80)

for metric in all_metrics:
    plt.figure(figsize=(18, 12))
    
    for method in methods:
        method_data = df[df["Method"] == method]
        plt.plot(
            method_data["Load"],
            method_data[f"Normalized_{metric}"],
            marker=markers[method],
            linestyle=line_styles[method],
            color=color_map[method],
            linewidth=6,
            markersize=20,
            label=name_mapping[method]
        )
    
    # å›¾è¡¨ç»†èŠ‚é…ç½®
    title, filename, legend_config = metric_config[metric]
    plt.xlabel("Load(%)", fontsize=60)
    plt.ylabel("Normalized FCT", fontsize=60)
    # plt.title(title, fontsize=14, pad=15)
    plt.grid(True, axis='y', linestyle='', alpha=0.6)
    
    # å›¾ä¾‹é…ç½®
    plt.legend(
        frameon=False,
        framealpha=0.9,
        shadow=False,
        edgecolor='black',
        facecolor='white',
        labelspacing=0.4,
        handlelength=2.0,
        handletextpad=0.8,
        fontsize=50,
        title=None,
        **legend_config
    )
    
    plt.xticks(load_values, [f"{int(load*100)}" for load in load_values])
    plt.ylim(bottom=0.98)
    
    # ä¿å­˜PDFæ–‡ä»¶
    pdf_filename = f"normalized_{metric_config[metric][1]}.pdf"
    pdf_path = output_dir / pdf_filename
    plt.tight_layout()
    plt.savefig(pdf_path, dpi=300, bbox_inches="tight", format="pdf")
    plt.close()
    print(f"âœ… å·²ä¿å­˜ï¼š{pdf_filename}")

# -------------------------- è¾“å‡ºæ±‡æ€»ä¿¡æ¯ --------------------------
print(f"\n" + "="*80)
print(f"ğŸ“ æ‰€æœ‰å›¾è¡¨ä¿å­˜è·¯å¾„ï¼š{output_dir}")
print(f"âœ… å…±ç”Ÿæˆ {len(all_metrics)} ä¸ªå›¾è¡¨æ–‡ä»¶")
print("="*80)

print(f"\nğŸ’¡ å°ºå¯¸åˆ†ç‰‡æŒ‡æ ‡å›¾è¡¨ï¼š")
for metric in size_metrics:
    print(f"  - normalized_{metric_config[metric][1]}.pdf")